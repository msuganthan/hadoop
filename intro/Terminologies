Terminologies:
==============

	JobTracker
	==========

	Is a service within Hadoop that farms out MapReduce tasks to specific nodes in the cluster, ideally the nodes that have the data, or atleast are in the same rack.

	1. Client applications submit jobs to the Job tracker. 
	2. The JobTracker talks to the NameNode to determine the location of the data
	3. The JobTracker locates TaskTracker nodes with available slots at or near the data 
	4. The JobTracker submits the work to the chosen TaskTracker nodes.
	5. The TaskTracker nodes are monitored. If they do not submit heartbeat signals often enough, they are deemed to have failed and the work is scheduled on a different TaskTracker. 
	6. A TaskTracker will notify the JobTracker when a task fails. The JobTracker decides what to do then: it may resubmit the job elsewhere, it may mark that specific record as something to avoid, and it may may even blacklist the TaskTracker as unreliable. 
	7. When the work is completed, the JobTracker updates its status. 
	8. Client applications can poll the JobTracker for information. 

	The JobTracker is a point of failure for the Hadoop MapReduce service. If it goes down, all running jobs are halted. 

	TaskTrackers:
	=============

	Is a node in the cluster that accepts task - Map, Reduce and Shuffle operations.

	1. Every TaskTracker is configured with a set of slots, these indicated the number of task that it can accept. 
	2. When the JobTracker tries to find somewhere to schedule a task within the MapReduce operations, it first looks for an empty slot on the same server that host the DataNode containing the data, if not, it looks for an empty slot on a machine in the same rack.

	The TaskTracker spawns a seperate JVM processes to do the actual work; this is to ensure that process failure does not take down the task tracker. The TaskTracker monitor these spawned processes, capturing the output and exit codes. When the process finishes, successfully or not, the tracker notifies the JobTracker. The TaskTracker also sends the heart-beat message to the JobTracker that it is still alive. These message also inform the JobTracker the number of available slot, so the JobTracker can stay up to data with where in the cluster work can be delegated.

	NameNode:
	=========

	Is a centerpiece of an HDFS file system. 

	It keeps the directory tree of all files in the file system, and tracks where across the cluster the file data is kept. It does not store the data of these files itself. 

	Client applications talk to the NameNode whenever they wish to locate a file, or when they want to add/copy/move/delete a file. The NameNode responds the successful requests by returning a list of relevant DataNode servers where the data lives. 

	The NameNode is a Single Point of Failure for the HDFS Cluster. HDFS is not currently a High Availability system. When the NameNode goes down, the file system goes offline. There is an optional SecondaryNameNode that can be hosted on a separate machine.

	
